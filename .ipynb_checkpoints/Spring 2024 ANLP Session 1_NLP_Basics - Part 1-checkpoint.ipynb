{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ecJmPhZFA-m2iFqpCRBlSTI88q1lDJjh","timestamp":1722921391850},{"file_id":"1IWfuX-hEoevpkjQ2HIh9-WkocbtjL52L","timestamp":1722582784714},{"file_id":"1c9UrlZBtB9TDzVW-x5iexE_AGVoKznw2","timestamp":1720086363941},{"file_id":"1bX8KG9eYFB7oXU159tGKpPmft8HxPXKl","timestamp":1677471220893},{"file_id":"18f2tjoUjCg25WCD4S8UhP4CKfNo5IHZn","timestamp":1677426098486},{"file_id":"1nnKc9LV3EUDEKYJ9Z4ziLFIgs9HWC4OC","timestamp":1677418318585}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# tinyurl.com/ANLPcolab1\n","\n"],"metadata":{"id":"bFZV-SOzr6vq"}},{"cell_type":"markdown","source":["# Basics of Natural Language Processing (NLP) #\n","\n","*CoLab Tutorial*\n","\n","This notebook demonstrates some basic NLP tasks to get you started on text analysis.\n","\n","Run each block one by one in order of occurence to get the results. Have a play with the cells by editing the code and examining the new output(s)."],"metadata":{"id":"8AhFOUj6iCWG"}},{"cell_type":"markdown","source":["# Run this code in the beginning to limit the output size of the cells\n","\n","This is just an initial set up to make sure our cells are displayed properly"],"metadata":{"id":"fxBFGZ8DadFp"}},{"cell_type":"code","source":["from IPython.display import display, Javascript\n","\n","def resize_colab_cell():\n","  # Change the maxHeight variable to change the max height of the output\n","   display(Javascript('google.colab.output.setIframeHeight(0, true, {maxHeight: 400})'))\n","  #Change output size for the entire notebook (set to call function on cell run)\n","   get_ipython().events.register('pre_run_cell', resize_colab_cell)"],"metadata":{"id":"8HBE7ck1XPX_","executionInfo":{"status":"ok","timestamp":1723522407118,"user_tz":-600,"elapsed":3,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## 1. Input Text\n","\n","There are many ways we can provide an input text for analysis. We will go through three ways in this notebook\n","\n","\n","1.   Define input text in a variable\n","2.   Scrape text from a web source\n","3.   Read from a file\n","\n","Defining input text in a variable and scraping text from a web source will be demonstrated in class.\n","\n","To get started, we provide a sample text for analysis. We analyse the **components of the text** to teach the machine to make sense of it.\n"],"metadata":{"id":"jT3X0RuyndZi"}},{"cell_type":"code","source":["# Assign text (in the form of a multiline string) to a variable 'mytext'\n","\n","mytext = \"\"\"\n","Have we reached (hu)man-machine symbiosis where we do not simply use technology but are enmeshed with technology in “socio-cyborgian activity systems,” as Bazerman notes?\n","\n","While we are certainly in an age where technology plays an increasingly important role in our daily lives, we have not yet fully reached a state of human-machine symbiosis. However, there are certainly elements of symbiosis that can be seen in certain domains.\n","\n","For example, in some professions such as medicine or aviation, technology plays an integral role in supporting human decision-making and action. In these domains, technology and humans work together to achieve a common goal, and the relationship between the two can be seen as a kind of symbiosis.\n","\n","However, in other domains such as social media or gaming, the relationship between humans and technology is more complex and often less symbiotic. In these domains, technology can sometimes be seen as a distraction or even a hindrance to human activity, rather than a support.\n","\n","Overall, while the relationship between humans and technology is undoubtedly becoming more intertwined, it is still evolving and we have not yet reached a full state of symbiosis in all areas of our lives\n","\"\"\".strip()\n","\n","# Check if the variable contains the intended text\n","print(mytext)"],"metadata":{"id":"z_GujJQgg8Qn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723522407118,"user_tz":-600,"elapsed":2,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"ee92fdf2-230f-4512-b79d-7ce85ded942a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Have we reached (hu)man-machine symbiosis where we do not simply use technology but are enmeshed with technology in “socio-cyborgian activity systems,” as Bazerman notes?\n","\n","While we are certainly in an age where technology plays an increasingly important role in our daily lives, we have not yet fully reached a state of human-machine symbiosis. However, there are certainly elements of symbiosis that can be seen in certain domains.\n","\n","For example, in some professions such as medicine or aviation, technology plays an integral role in supporting human decision-making and action. In these domains, technology and humans work together to achieve a common goal, and the relationship between the two can be seen as a kind of symbiosis.\n","\n","However, in other domains such as social media or gaming, the relationship between humans and technology is more complex and often less symbiotic. In these domains, technology can sometimes be seen as a distraction or even a hindrance to human activity, rather than a support.\n","\n","Overall, while the relationship between humans and technology is undoubtedly becoming more intertwined, it is still evolving and we have not yet reached a full state of symbiosis in all areas of our lives\n"]}]},{"cell_type":"markdown","source":["Check out what happens when you don't use \" \" \"  for multi-line texts. Learn more about Python strings here and try different inputs: https://www.w3schools.com/python/python_strings.asp"],"metadata":{"id":"TMeVOWZ2udAM"}},{"cell_type":"markdown","source":["### Using web scraping"],"metadata":{"id":"PnRqbRfLzq-k"}},{"cell_type":"markdown","source":["The following code demonstrates the use of a web scraping library called BeautifulSoup . You may try different Web scraping methods from [here](https://realpython.com/python-web-scraping-practical-introduction/) if you are interested, but the code shows a simple example to extract data from a web page using the page's HTML tags and attributes."],"metadata":{"id":"5rWTYRGO6x30"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","# Send a GET request to the website\n","response = requests.get('https://handbook.uts.edu.au/subjects/details/36118.html')\n","\n","# Parse the HTML content of the page\n","soup = BeautifulSoup(response.text, 'html.parser')\n","#The above line creates a BeautifulSoup object from the HTML content of the response. It uses the 'html.parser' to parse the HTML\n","\n","# Find the required information using HTML tags and attributes\n","title = soup.find_all('h1')[0].text  # finds all <h1> tags in the HTML and takes the text of the first one (index 0) - assumed to be the title of the page\n","subject_code = title.split(' ')[0]  # splits the title by spaces and takes the first part, assuming it is the subject code\n","subject_name = ' '.join(title.split(' ')[1:])  #takes all parts of the title after the first space and joins them back together, assuming this is the subject name\n","subject_description = soup.h3.next_sibling.next_sibling.next_element.text #This line is more complex - It starts from the first <h3> tag in the document. It then moves to the next sibling twice (.next_sibling.next_sibling). Finally, it gets the next element and its text. This assumes that the subject description is located two siblings after an <h3> tag.\n","\n","# Print the scraped information\n","print(f\"Page Title: {title}\")\n","print(f\"Subject Code: {subject_code}\")\n","print(f\"Subject Name: {subject_name}\")\n","print(f\"Subject Description: {subject_description}\")"],"metadata":{"id":"oBu9Dk8tIJwA","colab":{"base_uri":"https://localhost:8080/","height":634},"executionInfo":{"status":"error","timestamp":1723522418236,"user_tz":-600,"elapsed":11119,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"1f7679ae-ab83-4790-8715-43e8d2f1f3d0"},"execution_count":3,"outputs":[{"output_type":"error","ename":"SSLError","evalue":"HTTPSConnectionPool(host='handbook.uts.edu.au', port=443): Max retries exceeded with url: /subjects/details/36118.html (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)')))","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSSLEOFError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n\u001b[0m\u001b[1;32m    643\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[0;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m     ssl_sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0mssl_sock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ssl_wrap_socket_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mssl_sock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1370\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSSLEOFError\u001b[0m: [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_proxy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSSLError\u001b[0m: [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreason\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='handbook.uts.edu.au', port=443): Max retries exceeded with url: /subjects/details/36118.html (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)')))","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-23ab52c160c3>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Send a GET request to the website\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://handbook.uts.edu.au/subjects/details/36118.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Parse the HTML content of the page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0;31m# This branch is for urllib3 v1.22 and later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSSLError\u001b[0m: HTTPSConnectionPool(host='handbook.uts.edu.au', port=443): Max retries exceeded with url: /subjects/details/36118.html (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)')))"]}]},{"cell_type":"markdown","source":["Note: This code assumes a very specific HTML structure. If the structure changes, the code might break. For more robust parsing, you might want to use more specific selectors (like IDs or classes) if they're available in the HTML, or add error handling to deal with cases where the expected structure isn't found."],"metadata":{"id":"vSrrTGBryVIU"}},{"cell_type":"markdown","source":["### Text representation"],"metadata":{"id":"b80-n7nUzKoL"}},{"cell_type":"markdown","source":["Low level computer representations of text do not equate to simple human understandings of text. A simple illustration can be seen by how much difference it makes to distinguish between words, sentences and paragraphs.\n","\n","*This is a sample sentence I wrote*\n","\n","Notice that as this is just a **string** of characters, it doesn't include any of the normal formatting that we associate with text.\n","To make it more readable, we can display the text as HTML in the output of the cell - the browser will parse it in a way that makes it easier to see the whole text. This is basic text visualisation in the browser."],"metadata":{"id":"Lt8UK74sjgqn"}},{"cell_type":"code","source":["# import display.HTML and use it display the text as HTML\n","from IPython.display import HTML\n","HTML(mytext)"],"metadata":{"id":"9s5E5xBWh28_","executionInfo":{"status":"aborted","timestamp":1723522418237,"user_tz":-600,"elapsed":3,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","We could make it more readable still by turning the text into a list of paragraphs and displaying each with a space between."],"metadata":{"id":"1lU5LtTUkRJd"}},{"cell_type":"code","source":["# create a list of paragraphs\n","\n","mytext_paras = mytext.split('\\n')\n","\n","# wrap each paragraph in html <p> tags and separate with a </br> tag\n","html_mytext = '</br>'.join(map(lambda x: '<p>'+x+'</p>', mytext_paras))\n","\n","HTML(html_mytext)"],"metadata":{"id":"3TrJN19UkrF-","executionInfo":{"status":"aborted","timestamp":1723522418237,"user_tz":-600,"elapsed":2,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Basic Analysis\n","\n","To perform analysis on text, we generally make use of NLP libraries. Two of the most common libraries for the Python language are `Spacy` and `NLTK`. We will use NLTK for our first analysis."],"metadata":{"id":"UI_3GXkzn5U9"}},{"cell_type":"code","source":["#Import and load the NLTK library\n","import nltk\n","from  nltk.tokenize  import  sent_tokenize ,  word_tokenize\n","nltk.download('punkt')"],"metadata":{"id":"LA1TsIq3dFCI","executionInfo":{"status":"aborted","timestamp":1723522418237,"user_tz":-600,"elapsed":2,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tokenization"],"metadata":{"id":"QUGUdF6U0CWY"}},{"cell_type":"markdown","source":["We're now ready to process our text with NLTK. For this exercise, we'll just do simple analysis starting with tokenization."],"metadata":{"id":"SR2HwGvtqURV"}},{"cell_type":"code","source":["mytextsents = sent_tokenize(mytext)\n","mytextsents"],"metadata":{"id":"cIr35TVu58tu","executionInfo":{"status":"aborted","timestamp":1723522418237,"user_tz":-600,"elapsed":2,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mytextwords = word_tokenize(mytext)\n","mytextwords"],"metadata":{"id":"r8rxsUZv7xRy","executionInfo":{"status":"aborted","timestamp":1723522418237,"user_tz":-600,"elapsed":2,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Parts of Speech (POS) tagging"],"metadata":{"id":"CTxoeIuF-Ow7"}},{"cell_type":"markdown","source":["We can also identify the parts-of-speech in the text using NLTK predefined taggers"],"metadata":{"id":"6W8He74Q-Mzc"}},{"cell_type":"code","source":["nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.help.upenn_tagset()\n","\n","mytextpos = nltk.pos_tag(mytextwords)\n","mytextpos"],"metadata":{"id":"gqWpQChz8Yxk","executionInfo":{"status":"aborted","timestamp":1723522418237,"user_tz":-600,"elapsed":2,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And display the dependency tree..."],"metadata":{"id":"X9d86i_j0LD5"}},{"cell_type":"code","source":["!pip install svgling #The svgling package is a pure python package for doing single-pass rendering of linguistics-style constituent trees into SVG\n","nltk.download(\"maxent_ne_chunker\")\n","nltk.download(\"words\")\n","tree = nltk.ne_chunk(mytextpos)\n","display(tree)"],"metadata":{"id":"VQMIMd8A_Ycw","executionInfo":{"status":"aborted","timestamp":1723522418237,"user_tz":-600,"elapsed":2,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that NLTK returns strings it found as words, but it also includes ')', ', etc."],"metadata":{"id":"mmJcEpzF74Q0"}},{"cell_type":"markdown","source":["### Named Entity Recognition (NER)\n","\n","Now let's try NER using the Spacy package which also has many other linguistic features (see https://spacy.io/usage/linguistic-features for more)"],"metadata":{"id":"KAtzyNpP7fD2"}},{"cell_type":"code","source":["# Load the spacy library and a pre-trained language model for English text\n","\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"id":"BcRHdysv7d7A","executionInfo":{"status":"ok","timestamp":1723522427834,"user_tz":-600,"elapsed":8025,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Process text\n","doc = nlp(mytext)"],"metadata":{"id":"eHohvmRY7rMx","executionInfo":{"status":"ok","timestamp":1723522427834,"user_tz":-600,"elapsed":3,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Extract entities\n","\n","for entity in doc.ents:\n","    print(f\"Entity: {entity.text}, Label: {entity.label_}\")"],"metadata":{"id":"ZpQ2SOpZ7vMK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723522427835,"user_tz":-600,"elapsed":3,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"3a448f72-c852-4a96-fd42-9085694b0f14"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Entity: Bazerman, Label: PERSON\n","Entity: two, Label: CARDINAL\n"]}]},{"cell_type":"code","source":["# These entities can be visualised\n","\n","import IPython\n","\n","from spacy import displacy\n","ent_render = displacy.render(doc, style=\"ent\")\n","IPython.display.HTML(ent_render)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"id":"DXEuaPL08oNT","executionInfo":{"status":"ok","timestamp":1723522427835,"user_tz":-600,"elapsed":3,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"be86ca10-a38f-435a-dd27-0e0c511870fe"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Have we reached (hu)man-machine symbiosis where we do not simply use technology but are enmeshed with technology in “socio-cyborgian activity systems,” as \n","<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Bazerman\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n","</mark>\n"," notes?<br><br>While we are certainly in an age where technology plays an increasingly important role in our daily lives, we have not yet fully reached a state of human-machine symbiosis. However, there are certainly elements of symbiosis that can be seen in certain domains.<br><br>For example, in some professions such as medicine or aviation, technology plays an integral role in supporting human decision-making and action. In these domains, technology and humans work together to achieve a common goal, and the relationship between the \n","<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    two\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n","</mark>\n"," can be seen as a kind of symbiosis.<br><br>However, in other domains such as social media or gaming, the relationship between humans and technology is more complex and often less symbiotic. In these domains, technology can sometimes be seen as a distraction or even a hindrance to human activity, rather than a support.<br><br>Overall, while the relationship between humans and technology is undoubtedly becoming more intertwined, it is still evolving and we have not yet reached a full state of symbiosis in all areas of our lives</div></span>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":[],"metadata":{"id":"xnGQqG-k7tmq"}},{"cell_type":"markdown","source":["# 3. Regular expressions\n","\n","A **regular expression** (or RE) is used to match strings of text such as particular characters, words, or patterns of characters. These come in quite handy for a number of operations in string manipulation. For instance, we can extract name from an email ID, Title from a name, subject code from a text description, or components of an address.\n","\n","There are commonly used wild card patterns in Python that helps us extract useful information from texts:\n","^\n","\n","This wild card matches the characters at the beginning of a line.\n","\n","$\n","\n","This wild card matches the characters at the end of the line.\n","\n",".\n","\n","This wild card matches any character in the line.\n","\n","s\n","\n","This wild card is used to match space in a string.\n","\n","S\n","\n","This wild card matches non-whitespace characters.\n","\n","d\n","\n","This wild card matches one digit.\n","\n","*\n","\n","This wild card repeats any preceding character zero or more times. It matches the longest possible string.\n","\n","*?\n","\n","This wild card also repeats any preceding character/characters zero or more times. However, it matches the shortest string following the pattern.\n","\n","+\n","\n","This wild card repeats any preceding character one or more times. It matches the longest possible string following the pattern.\n","\n","+?\n","\n","This wild card repeats any preceding character one or more times. However, it matches the shortest possible string following the pattern.\n","\n","[aeiou]\n","\n","It matches any character from a set of given characters.\n","\n","[^XYZ]\n","\n","It matches any character not given in the set.\n","\n"," [a-z0-9]\n","\n","It matches any character given in the a-z or 0-9.\n","\n","(\n","\n","This wild card represents the beginning of the string extraction.\n","\n",")\n","\n","This wild card represents the end of the string extraction.\n","\n","\n","Read examples of applications here: https://code.tutsplus.com/tutorials/8-regular-expressions-you-should-know--net-6149, and more examples here: https://developers.google.com/edu/python/regular-expressions"],"metadata":{"id":"d_BakwfDQ5zL"}},{"cell_type":"code","source":["!pip install regex\n","import regex as re\n","\n","test_string = '''\n","36118 Applied Natural Language Processing\n","Warning: The information on this page is indicative. The subject outline for a particular session, location and mode of offering is the authoritative source of all information about the subject for that offering. Required texts, recommended texts and references in particular are likely to change. Students will be provided with a subject outline once they enrol in the subject.\n","\n","Subject handbook information prior to 2024 is available in the Archives.\n","\n","UTS: Transdisciplinary Innovation\n","Credit points: 8 cp\n","Result type: Grade, no marks\n","\n","Requisite(s): 36100 Data Science for Innovation AND 36103 Statistical Thinking for Data Science AND 36106 Machine Learning Algorithms and Applications\n","Description\n","This subject introduces students to the complexities of human language data and the use of Natural Language Processing (NLP) and text mining techniques to analyse them. Students develop both technical and communicative skills to process and interpret unstructured textual data with a range of practical applications. Covering core NLP concepts and the latest developments in large language models, the course equips students with skills for insightful pattern discovery in natural language text, while emphasising ethical considerations.\n","\n","Subject learning objectives (SLOs)\n","Upon successful completion of this subject students should be able to:\n","\n","1.\tUnderstand core concepts of Natural Language Processing (NLP) and computational linguistics including its limitations (CILO 2.2, 2.3)\n","2.\tEvaluate complex challenges for problem solving and build practical NLP applications (CILO 2.3, 4.2)\n","3.\tApply text mining techniques on unstructured data sets using advanced NLP programming packages (CILOs 1.2, 2.2)\n","4.\tInterpret, extract value and effectively communicate insights from text analysis and create real-world applications suitable to a range of audiences (CILOs 2.4, 3.2, 4.2)\n","5.\tArticulate the strengths, weaknesses and underlying assumptions of NLP and text analysis to apply ethical practices (CILO 5.1, 5.2)\n","Contribution to the development of graduate attributes\n","1.2 Explore and test models and generalisations for describing the behaviour of sociotechnical systems and selecting data sources, taking into account the needs and values of different contexts and stakeholders\n","\n","2.2 Explore, analyse, manipulate, interpret and visualise data using data science techniques, software and technologies to make sense of data rich environments\n","\n","2.3 Understand and deal critically and openly with the uncertainty, ambiguity and complexity associated with people, systems and data\n","\n","2.4 Apply and assess data science concepts, theories, practices and tools for designing and managing data discovery investigations in professional environments that draw upon diverse data sources, including efforts to shed light on underrepresented components\n","\n","3.2 Critically examine the perceived value of data analytics outcomes and clearly articulate implications for different stakeholders and organisations\n","\n","4.2 Explore and craft interpretative narratives that engage key audiences with data analytics and potential significance for action, at a societal, industrial, organisational, group or individual levels\n","\n","5.1 Engage in active, reflective practice that supports flexible navigation of assumptions, alternatives and uncertainty in professional data science contexts\n","\n","5.2 Interrogate and justify ethical responsibilities related to data selection, access, analysis and governance to create a framework for practice\n","\n","Graduate attributes\n","\n","GA 1 Sociotechnical systems thinking\n","\n","GA 2 Creative, analytical and rigorous sense making\n","\n","GA 3 Create value in problem solving and inquiry\n","\n","GA 4 Persuasive and robust communication\n","\n","GA 5 Ethical citizenship\n","\n","Teaching and learning strategies\n","Blend of online and face to face activities: The subject is offered through a series of teaching sessions which blend online and face-to-face learning. Students learn through interactive lectures and classroom activities making use of the subject materials on canvas. They also engage in individual and collaborative learning activities to understand and apply text analysis techniques in diverse settings.\n","\n","Authentic problem based learning: This subject offers a range of authentic data science problems to solve that will help develop students’ text analysis skills. They work on real world data analysis problems for broad areas of interest using unstructured data and contemporary techniques.\n","\n","Collaborative work: Group activities will enable students to leverage peer-learning and demonstrate effective team participation, as well as learning to work in professional teams with an appreciation of diverse perspectives on data science and innovation.\n","\n","Future-oriented strategies: Students will be exposed to contemporary learning models using speculative thinking, ethical and human-centered approaches as well as reflection. Electronic portfolios will be used to curate, consolidate and provide evidence of learning and development of course outcomes, graduate attributes and professional evolution. Formative feedback will be offered with all assessment activities for successful engagement.\n","\n","Content (topics)\n","• Introduction to unstructured data and natural language text\n","• Foundations of Natural Language Processing (NLP)\n","• Text analysis techniques using Python\n","• Advanced NLP and Deep Learning\n","• Natural Language Understanding (NLU) and Natural Language Generation (NLG)\n","• Large Language Models (LLMs)\n","• Real-world applications of NLP\n","• Ethical best practices in NLP\n","\n","Assessment\n","Assessment task 1: Assessment 1: Text Analysis\n","Intent:\n","Assessment 1: Text Analysis\n","\n","NLP for data analysis (Python code + Markdown report) (Individual, 30%)\n","\n","Type:\tReport\n","Groupwork:\tIndividual\n","Weight:\t30%\n","Assessment task 2: Assessment 2: End-to-end NLP project\n","Intent:\n","Assessment 2: End-to-end NLP project\n","\n","· Part A: Design and development of a NLP application - Group project report and peer review (Group & Individual, 40%)\n","\n","· Part B: Final Presentation (Group, 10%)\n","\n","Type:\tReport\n","Groupwork:\tGroup, group and individually assessed\n","Weight:\t50%\n","Assessment task 3: Assessment 3: Critical Reflection\n","Intent:\n","Critical Reflection on:\n","\n","Bias and fairness in NLP\n","Personal learning and portfolio\n","(Individual, 20%)\n","\n","A detailed assessment brief will be made available on Canvas once the assignment tasks are released during in-class sessions.\n","\n","Type:\tReflection\n","Groupwork:\tIndividual\n","Weight:\t20%\n","Minimum requirements\n","1. Students must participate in all online and face to face requirements\n","2. Pass all assessment tasks\n","'''\n","print(test_string)\n"],"metadata":{"id":"pArnx7X5RfGv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722921861258,"user_tz":-600,"elapsed":3258,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"2640c7bd-bbdb-48d6-9bfc-dc95b31e5575"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2024.5.15)\n","\n","36118 Applied Natural Language Processing\n","Warning: The information on this page is indicative. The subject outline for a particular session, location and mode of offering is the authoritative source of all information about the subject for that offering. Required texts, recommended texts and references in particular are likely to change. Students will be provided with a subject outline once they enrol in the subject.\n","\n","Subject handbook information prior to 2024 is available in the Archives.\n","\n","UTS: Transdisciplinary Innovation\n","Credit points: 8 cp\n","Result type: Grade, no marks\n","\n","Requisite(s): 36100 Data Science for Innovation AND 36103 Statistical Thinking for Data Science AND 36106 Machine Learning Algorithms and Applications\n","Description\n","This subject introduces students to the complexities of human language data and the use of Natural Language Processing (NLP) and text mining techniques to analyse them. Students develop both technical and communicative skills to process and interpret unstructured textual data with a range of practical applications. Covering core NLP concepts and the latest developments in large language models, the course equips students with skills for insightful pattern discovery in natural language text, while emphasising ethical considerations.\n","\n","Subject learning objectives (SLOs)\n","Upon successful completion of this subject students should be able to:\n","\n","1.\tUnderstand core concepts of Natural Language Processing (NLP) and computational linguistics including its limitations (CILO 2.2, 2.3)\n","2.\tEvaluate complex challenges for problem solving and build practical NLP applications (CILO 2.3, 4.2)\n","3.\tApply text mining techniques on unstructured data sets using advanced NLP programming packages (CILOs 1.2, 2.2)\n","4.\tInterpret, extract value and effectively communicate insights from text analysis and create real-world applications suitable to a range of audiences (CILOs 2.4, 3.2, 4.2)\n","5.\tArticulate the strengths, weaknesses and underlying assumptions of NLP and text analysis to apply ethical practices (CILO 5.1, 5.2)\n","Contribution to the development of graduate attributes\n","1.2 Explore and test models and generalisations for describing the behaviour of sociotechnical systems and selecting data sources, taking into account the needs and values of different contexts and stakeholders\n","\n","2.2 Explore, analyse, manipulate, interpret and visualise data using data science techniques, software and technologies to make sense of data rich environments\n","\n","2.3 Understand and deal critically and openly with the uncertainty, ambiguity and complexity associated with people, systems and data\n","\n","2.4 Apply and assess data science concepts, theories, practices and tools for designing and managing data discovery investigations in professional environments that draw upon diverse data sources, including efforts to shed light on underrepresented components\n","\n","3.2 Critically examine the perceived value of data analytics outcomes and clearly articulate implications for different stakeholders and organisations\n","\n","4.2 Explore and craft interpretative narratives that engage key audiences with data analytics and potential significance for action, at a societal, industrial, organisational, group or individual levels\n","\n","5.1 Engage in active, reflective practice that supports flexible navigation of assumptions, alternatives and uncertainty in professional data science contexts\n","\n","5.2 Interrogate and justify ethical responsibilities related to data selection, access, analysis and governance to create a framework for practice\n","\n","Graduate attributes\n","\n","GA 1 Sociotechnical systems thinking\n","\n","GA 2 Creative, analytical and rigorous sense making\n","\n","GA 3 Create value in problem solving and inquiry\n","\n","GA 4 Persuasive and robust communication\n","\n","GA 5 Ethical citizenship\n","\n","Teaching and learning strategies\n","Blend of online and face to face activities: The subject is offered through a series of teaching sessions which blend online and face-to-face learning. Students learn through interactive lectures and classroom activities making use of the subject materials on canvas. They also engage in individual and collaborative learning activities to understand and apply text analysis techniques in diverse settings.\n","\n","Authentic problem based learning: This subject offers a range of authentic data science problems to solve that will help develop students’ text analysis skills. They work on real world data analysis problems for broad areas of interest using unstructured data and contemporary techniques.\n","\n","Collaborative work: Group activities will enable students to leverage peer-learning and demonstrate effective team participation, as well as learning to work in professional teams with an appreciation of diverse perspectives on data science and innovation.\n","\n","Future-oriented strategies: Students will be exposed to contemporary learning models using speculative thinking, ethical and human-centered approaches as well as reflection. Electronic portfolios will be used to curate, consolidate and provide evidence of learning and development of course outcomes, graduate attributes and professional evolution. Formative feedback will be offered with all assessment activities for successful engagement.\n","\n","Content (topics)\n","• Introduction to unstructured data and natural language text\n","• Foundations of Natural Language Processing (NLP)\n","• Text analysis techniques using Python\n","• Advanced NLP and Deep Learning\n","• Natural Language Understanding (NLU) and Natural Language Generation (NLG)\n","• Large Language Models (LLMs)\n","• Real-world applications of NLP\n","• Ethical best practices in NLP\n","\n","Assessment\n","Assessment task 1: Assessment 1: Text Analysis\n","Intent:\n","Assessment 1: Text Analysis\n","\n","NLP for data analysis (Python code + Markdown report) (Individual, 30%)\n","\n","Type:\tReport\n","Groupwork:\tIndividual\n","Weight:\t30%\n","Assessment task 2: Assessment 2: End-to-end NLP project\n","Intent:\n","Assessment 2: End-to-end NLP project\n","\n","· Part A: Design and development of a NLP application - Group project report and peer review (Group & Individual, 40%)\n","\n","· Part B: Final Presentation (Group, 10%)\n","\n","Type:\tReport\n","Groupwork:\tGroup, group and individually assessed\n","Weight:\t50%\n","Assessment task 3: Assessment 3: Critical Reflection\n","Intent:\n","Critical Reflection on:\n","\n","Bias and fairness in NLP\n","Personal learning and portfolio\n","(Individual, 20%)\n","\n","A detailed assessment brief will be made available on Canvas once the assignment tasks are released during in-class sessions.\n","\n","Type:\tReflection\n","Groupwork:\tIndividual\n","Weight:\t20%\n","Minimum requirements\n","1. Students must participate in all online and face to face requirements\n","2. Pass all assessment tasks\n","\n"]}]},{"cell_type":"markdown","source":["In the example below, we extract all words that start with the letter 'C'"],"metadata":{"id":"Ajz_B84pdPJ2"}},{"cell_type":"code","source":["startswithC = re.findall(r'(C\\w+)', test_string)\n","\n","for txt in startswithC:\n","    print(txt)"],"metadata":{"id":"kSB2PzQuTNIq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722921864301,"user_tz":-600,"elapsed":571,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"bf7c37fe-4b9d-4b09-87ac-38a25edf73b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Credit\n","Covering\n","CILO\n","CILO\n","CILOs\n","CILOs\n","CILO\n","Contribution\n","Critically\n","Creative\n","Create\n","Collaborative\n","Content\n","Critical\n","Critical\n","Canvas\n"]}]},{"cell_type":"code","source":["#Note how they are case-sensitive\n","startswithc = re.findall(r'(c\\w+)', test_string)\n","\n","for txt in startswithc:\n","    print(txt)"],"metadata":{"id":"q7mVC9vniJvi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722921874551,"user_tz":-600,"elapsed":524,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"b6bf8e27-de3c-4852-a58b-c0928ad5df5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cessing\n","cative\n","ct\n","cular\n","cation\n","ce\n","ct\n","commended\n","ces\n","cular\n","change\n","ct\n","ce\n","ct\n","ct\n","chives\n","ciplinary\n","cp\n","cience\n","cal\n","cience\n","chine\n","cations\n","cription\n","ct\n","ces\n","complexities\n","cessing\n","chniques\n","chnical\n","communicative\n","cess\n","ctured\n","ctical\n","cations\n","core\n","concepts\n","course\n","covery\n","cal\n","considerations\n","ct\n","ctives\n","ccessful\n","completion\n","ct\n","core\n","concepts\n","cessing\n","computational\n","cs\n","cluding\n","complex\n","challenges\n","ctical\n","cations\n","chniques\n","ctured\n","ced\n","ckages\n","ct\n","ctively\n","communicate\n","create\n","cations\n","ces\n","culate\n","cal\n","ctices\n","cribing\n","ciotechnical\n","cting\n","ces\n","ccount\n","contexts\n","cience\n","chniques\n","chnologies\n","ch\n","critically\n","certainty\n","complexity\n","ciated\n","cience\n","concepts\n","ctices\n","covery\n","ces\n","cluding\n","components\n","cally\n","ceived\n","cs\n","comes\n","clearly\n","culate\n","cations\n","craft\n","ces\n","cs\n","cance\n","ction\n","cietal\n","ctive\n","ctive\n","ctice\n","certainty\n","cience\n","contexts\n","cal\n","ction\n","ccess\n","ce\n","create\n","ctice\n","ciotechnical\n","cal\n","communication\n","cal\n","citizenship\n","ching\n","ce\n","ce\n","ctivities\n","ct\n","ching\n","ch\n","ce\n","ce\n","ctive\n","ctures\n","classroom\n","ctivities\n","ct\n","canvas\n","collaborative\n","ctivities\n","chniques\n","ct\n","cience\n","ctured\n","contemporary\n","chniques\n","ctivities\n","ctive\n","cipation\n","ciation\n","ctives\n","cience\n","contemporary\n","culative\n","cal\n","centered\n","ches\n","ction\n","ctronic\n","curate\n","consolidate\n","ce\n","course\n","comes\n","ck\n","ctivities\n","ccessful\n","cs\n","ction\n","ctured\n","cessing\n","chniques\n","ced\n","cations\n","cal\n","ctices\n","code\n","ct\n","ct\n","cation\n","ct\n","cal\n","ction\n","cal\n","ction\n","ce\n","class\n","ction\n","cipate\n","ce\n","ce\n"]}]},{"cell_type":"markdown","source":["Note how it captures non-words as well. We need to adjust it to ensure we're only extracting complete words. Let's try the below:"],"metadata":{"id":"yMfQdeoUBCTI"}},{"cell_type":"code","source":["wordsthatstartwithc = re.findall(r'\\b(c\\w+)\\b', test_string)\n","\n","for txt in wordsthatstartwithc:\n","    print(txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"veF27bsPBSjE","executionInfo":{"status":"ok","timestamp":1722921914662,"user_tz":-600,"elapsed":481,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"dbf4a1d4-4756-49e2-88df-1951a0e18265"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["change\n","cp\n","complexities\n","communicative\n","core\n","concepts\n","course\n","considerations\n","completion\n","core\n","concepts\n","computational\n","complex\n","challenges\n","communicate\n","create\n","contexts\n","critically\n","complexity\n","concepts\n","components\n","clearly\n","craft\n","contexts\n","create\n","communication\n","citizenship\n","classroom\n","canvas\n","collaborative\n","contemporary\n","contemporary\n","centered\n","curate\n","consolidate\n","course\n","code\n","class\n"]}]},{"cell_type":"markdown","source":["#### Regular Expression Breakdown\n","\n","r'\\b(c\\w+)\\b'\n","\n","\n","Let's break down this improved regular expression:\n","\n","1. `\\b`: This is a word boundary anchor. It matches a position where a word character is not followed or preceded by another word character.\n","2. `(c\\w+)`: This is the main matching group:\n","    - `c`: Matches the literal character 'c'\n","    - `\\w+`: Matches one or more word characters (letters, digits, or underscores)\n","3. `\\b`: Another word boundary anchor at the end\n","\n","This pattern will now match complete words that:\n","\n","- Start with the letter 'c'\n","- Contain one or more additional word characters\n","- Are not part of a larger word\n","\n","Examples of what it will match:\n","\n","- \"cat\", \"computer\", \"code\", \"c123\"\n","\n","Examples of what it won't match:\n","\n","- \"incompatible\" (doesn't start with 'c')\n","- \"c-section\" (contains a hyphen)\n","- \"abc\" (doesn't start with 'c')"],"metadata":{"id":"GzMBJlRTB813"}},{"cell_type":"markdown","source":["Exercise: Can you try creating one that captures lower case or upper case characters?"],"metadata":{"id":"OEoAvuVpuKpY"}},{"cell_type":"code","source":[],"metadata":{"id":"Wbi0wdriedJn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's write a function that can return matching texts and test it out with RegEx patterns."],"metadata":{"id":"0ZJEcFrNdXpQ"}},{"cell_type":"code","source":["def find_with_regex(regex, text):\n","    matches = []\n","    # find all matching patterns\n","    for group in regex.findall(text):\n","        matchingtext = ''.join(group)\n","        matches.append(matchingtext)\n","\n","    print(\"All matching texts: \")\n","    print(matches)"],"metadata":{"id":"dU8no7-GVtHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Extracting any integer\n","pattern = re.compile(r'[0-9]')\n","find_with_regex(pattern, test_string)"],"metadata":{"id":"oouHlKhrW-Vw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722921935801,"user_tz":-600,"elapsed":3,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"b1161720-9b6d-4efa-bd3a-8de79ff79a5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All matching texts: \n","['3', '6', '1', '1', '8', '2', '0', '2', '4', '8', '3', '6', '1', '0', '0', '3', '6', '1', '0', '3', '3', '6', '1', '0', '6', '1', '2', '2', '2', '3', '2', '2', '3', '4', '2', '3', '1', '2', '2', '2', '4', '2', '4', '3', '2', '4', '2', '5', '5', '1', '5', '2', '1', '2', '2', '2', '2', '3', '2', '4', '3', '2', '4', '2', '5', '1', '5', '2', '1', '2', '3', '4', '5', '1', '1', '1', '3', '0', '3', '0', '2', '2', '2', '4', '0', '1', '0', '5', '0', '3', '3', '2', '0', '2', '0', '1', '2']\n"]}]},{"cell_type":"code","source":["#Extracting string with integers with at least 4 digits and at most 7 digits\n","pattern = re.compile(r'\\d{4,7}(?!\\d)')\n","find_with_regex(pattern, test_string)"],"metadata":{"id":"iYJjzdqTXSLB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722921942297,"user_tz":-600,"elapsed":474,"user":{"displayName":"Rodrigo Araya","userId":"15064802547271996259"}},"outputId":"a5a27e5b-0340-4453-cb3c-46bbcc440eae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All matching texts: \n","['36118', '2024', '36100', '36103', '36106']\n"]}]},{"cell_type":"markdown","source":["Note: match() will only match if the string starts with the pattern. search() module will return the first occurrence that matches the specified pattern. findall() will iterate over all the lines of the file and will return all non-overlapping matches of pattern in a single step\n"],"metadata":{"id":"T-XEFcwyYO5d"}},{"cell_type":"code","source":[],"metadata":{"id":"ieqPBWAbnv_t"},"execution_count":null,"outputs":[]}]}